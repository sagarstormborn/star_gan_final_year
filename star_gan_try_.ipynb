{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "star gan try .ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNbCt/Jqo2IbLImQq8jP1sT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sagarstormborn/star_gan_final_year/blob/main/star_gan_try_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPc5qo8lsNy0"
      },
      "source": [
        "cloning git "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RM4KkdZeq4f3",
        "outputId": "6bcc6900-1c6a-4cde-ca7b-df1d5c8008f0"
      },
      "source": [
        "!git clone https://github.com/hujinsen/StarGAN-Voice-Conversion"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'StarGAN-Voice-Conversion' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kkib8IwUrNym",
        "outputId": "7a822cb3-988e-44e3-e22a-30a405909c0b"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data  StarGAN-Voice-Conversion\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_lHuT8WsSj0",
        "outputId": "99b5023b-b820-409e-8b4f-dcd9906915ed"
      },
      "source": [
        "%cd  StarGAN-Voice-Conversion"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/StarGAN-Voice-Conversion\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yvpg7sMsa4A",
        "outputId": "9fc36ea3-62aa-43b6-ead4-4e649ec36fad"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mconverted_speech\u001b[0m/  \u001b[01;34mimgs\u001b[0m/      \u001b[01;32mmodule.py\u001b[0m*      \u001b[01;32mtrain.py\u001b[0m*\n",
            "convert.py         LICENSE    \u001b[01;32mpreprocess.py\u001b[0m*  utility.py\n",
            "download.py        \u001b[01;32mmodel.py\u001b[0m*  README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XNziVZ0scTv",
        "outputId": "ef14ae01-7212-4348-be13-cc5d084959d8"
      },
      "source": [
        "%cat README.md"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "## StarGAN Voice Conversion\n",
            "\n",
            "This is a tensorflow implementation of the paper: [StarGAN-VC: Non-parallel many-to-many voice conversion with star generative adversarial networks](https://arxiv.org/abs/1806.02169).\n",
            "\n",
            "\n",
            "\n",
            "**The converted voice examples are in *converted* directory**\n",
            "\n",
            "## Dependencies\n",
            "\n",
            "- Python 3.6 (or higher)\n",
            "- tensorflow 1.8\n",
            "- librosa \n",
            "- pyworld \n",
            "- tensorboard\n",
            "- scikit-learn\n",
            "\n",
            "> NOTE:According to some feedbacks, we recommend to use tensorflow version 1.8  exactly. (Tensorflow 1.11 generate nonsense results)\n",
            "\n",
            "## Usage\n",
            "\n",
            "#### Download dataset\n",
            "\n",
            "Download the vcc 2016 dataset to the current directory and create `train directory` and `test directory`.\n",
            "\n",
            "```\n",
            "python download.py --datasets vcc2016 --train_dir ./data/fourspeakers --test_dir ./data/fourspeakers_test\n",
            "\n",
            "For simplicity use:\n",
            "python download.py \n",
            "```\n",
            "\n",
            "The downloaded zip files are extracted to `./data/vcc2016_training` and `./data/evaluation_all`.\n",
            "\n",
            "1. **training set:** In the experiment, we choose **four speakers** from `./data/vcc2016_training`.  We  move the corresponding folder(eg. SF1,SF2,TM1,TM2 ) to `./data/fourspeakers`.\n",
            "2. **testing set** In the experiment, we choose **four speakers** from `./data/evaluation_all`.  We  move the corresponding folder(eg. SF1,SF2,TM1,TM2 ) to `./data/fourspeakers_test`.\n",
            "\n",
            "The data directory now looks like this:\n",
            "\n",
            "```\n",
            "data\n",
            "├── fourspeakers  (training set)\n",
            "│   ├── SF1\n",
            "│   ├── SF2\n",
            "│   ├── TM1\n",
            "│   └── TM2\n",
            "├── fourspeakers_test (testing set)\n",
            "│   ├── SF1\n",
            "│   ├── SF2\n",
            "│   ├── TM1\n",
            "│   └── TM2\n",
            "├── vcc2016_training (vcc 2016 training set)\n",
            "│   ├── ...\n",
            "├── evaluation_all (vcc 2016 evaluation set, we use it as testing set)\n",
            "│   ├── ...\n",
            "```\n",
            "\n",
            "\n",
            "\n",
            "#### Preprocess dataset\n",
            "\n",
            "Extract features (mcep, f0, ap) from each speech clip.  The features are stored as npy files. We also calculate the statistical characteristics for each speaker.\n",
            "\n",
            "```\n",
            "python preprocess.py --input_dir ./data/fourspeakers --output_dir ./data/processed --ispad True\n",
            "\n",
            "For simplicity use:\n",
            "python preprocess.py\n",
            "```\n",
            "\n",
            "This process may take a few minutes !\n",
            "\n",
            "**Note that test set doesn’t need preprocess.**\n",
            "\n",
            "\n",
            "\n",
            "#### Train\n",
            "\n",
            "Read npy files from `processed_dir` to train model and raw wav files from` test_wav_dir` to randomly generate some samples using the model during training.\n",
            "\n",
            "```\n",
            "python train.py --processed_dir ./data/processed --test_wav_dir ./data/fourspeakers_test\n",
            "\n",
            "For simplicity use:\n",
            "python train.py\n",
            "```\n",
            "\n",
            "\n",
            "\n",
            "#### Convert\n",
            "\n",
            "Restore model from `model_dir`, convert source_speaker’s speech to target_speaker’s speech. The results are strored in `./converted_voices`\n",
            "\n",
            "```\n",
            "python convert.py --model_dir ./your_model_dir  --source_speaker SF1 --target_speaker TM1\n",
            "```\n",
            "\n",
            "\n",
            "\n",
            "## Summary\n",
            "\n",
            "The network structure shown as follows:\n",
            "\n",
            "![Snip20181102_2](./imgs/Snip20181102_2.png)\n",
            "\n",
            "\n",
            "\n",
            "**Note: Our implementation follows the original paper’s network structure**, while [pytorch StarGAN-VC code](https://github.com/liusongxiang/StarGAN-Voice-Conversion)‘network is different from the paper as it’s classifier shares the Discriminator’s weights. Both ways generate good converted speeches.\n",
            "\n",
            "## Reference\n",
            "\n",
            "[CycleGAN-VC code](https://github.com/leimao/Voice_Converter_CycleGAN)\n",
            "\n",
            "[pytorch StarGAN-VC code](https://github.com/hujinsen/pytorch-StarGAN-VC)\n",
            "\n",
            "[StarGAN code](https://github.com/taki0112/StarGAN-Tensorflow)\n",
            "\n",
            "[StarGAN-VC paper](https://arxiv.org/abs/1806.02169)\n",
            "\n",
            "[StarGAN paper](https://arxiv.org/abs/1806.02169)\n",
            "\n",
            "[CycleGAN paper](https://arxiv.org/abs/1703.10593v4)\n",
            "\n",
            "---\n",
            "\n",
            "If you feel this repo is good, please  **star**  ! \n",
            "\n",
            "Your encouragement is my biggest motivation!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJuF8mV6snQ3",
        "outputId": "90c7f6de-fb91-4155-af13-44062f8112c6"
      },
      "source": [
        "!pip3 install librosa pyworld tensorboard scikit-learn"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.0)\n",
            "Requirement already satisfied: pyworld in /usr/local/lib/python3.7/dist-packages (0.2.12)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (0.22.2.post1)\n",
            "Requirement already satisfied: soundfile>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.3.0)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.1)\n",
            "Requirement already satisfied: cython>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from pyworld) (0.29.21)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.15.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.8.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.36.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (53.0.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.32.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.4.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.10.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.12.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (2.23.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.27.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.3.3)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.9.0->librosa) (1.14.5)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (20.9)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (4.7.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (4.2.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard) (3.4.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.9.0->librosa) (2.20)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pooch>=1.0->librosa) (2.4.7)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard) (3.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5x6wzatEs01c",
        "outputId": "022a84e5-7f46-45e7-ae2c-8f72a1e00699"
      },
      "source": [
        "%tensorflow_version 1.8\r\n",
        "import tensorflow\r\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.8`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n",
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hng1DgLltMGg",
        "outputId": "5491154a-f8ad-41bf-9bd1-028eba108204"
      },
      "source": [
        "# !pip install tensorflow==1.8.0"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==1.8.0 (from versions: 1.13.0rc1, 1.13.0rc2, 1.13.1, 1.13.2, 1.14.0rc0, 1.14.0rc1, 1.14.0, 1.15.0rc0, 1.15.0rc1, 1.15.0rc2, 1.15.0rc3, 1.15.0, 1.15.2, 1.15.3, 1.15.4, 1.15.5, 2.0.0a0, 2.0.0b0, 2.0.0b1, 2.0.0rc0, 2.0.0rc1, 2.0.0rc2, 2.0.0, 2.0.1, 2.0.2, 2.0.3, 2.0.4, 2.1.0rc0, 2.1.0rc1, 2.1.0rc2, 2.1.0, 2.1.1, 2.1.2, 2.1.3, 2.2.0rc0, 2.2.0rc1, 2.2.0rc2, 2.2.0rc3, 2.2.0rc4, 2.2.0, 2.2.1, 2.2.2, 2.3.0rc0, 2.3.0rc1, 2.3.0rc2, 2.3.0, 2.3.1, 2.3.2, 2.4.0rc0, 2.4.0rc1, 2.4.0rc2, 2.4.0rc3, 2.4.0rc4, 2.4.0, 2.4.1)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for tensorflow==1.8.0\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iD9poUZrt1Mb",
        "outputId": "497e49ae-54dd-4065-f0fa-d53ce7dd47b5"
      },
      "source": [
        "!python download.py --datasets vcc2016 --train_dir ./data/fourspeakers --test_dir ./data/fourspeakers_test\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "create train set dir ./data/fourspeakers\n",
            "create test set dir ./data/fourspeakers_test\n",
            "Start download dataset...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxM6Bh4ru8_b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}