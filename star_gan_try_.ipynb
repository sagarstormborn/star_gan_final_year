{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "star gan try .ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP54yhODsZqLp+JPwO5v2b+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sagarstormborn/star_gan_final_year/blob/main/star_gan_try_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPc5qo8lsNy0"
      },
      "source": [
        "cloning git "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RM4KkdZeq4f3",
        "outputId": "6bcc6900-1c6a-4cde-ca7b-df1d5c8008f0"
      },
      "source": [
        "!git clone https://github.com/hujinsen/StarGAN-Voice-Conversion"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'StarGAN-Voice-Conversion' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kkib8IwUrNym",
        "outputId": "7a822cb3-988e-44e3-e22a-30a405909c0b"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data  StarGAN-Voice-Conversion\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_lHuT8WsSj0",
        "outputId": "99b5023b-b820-409e-8b4f-dcd9906915ed"
      },
      "source": [
        "%cd  StarGAN-Voice-Conversion"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/StarGAN-Voice-Conversion\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yvpg7sMsa4A",
        "outputId": "9fc36ea3-62aa-43b6-ead4-4e649ec36fad"
      },
      "source": [
        "%ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mconverted_speech\u001b[0m/  \u001b[01;34mimgs\u001b[0m/      \u001b[01;32mmodule.py\u001b[0m*      \u001b[01;32mtrain.py\u001b[0m*\n",
            "convert.py         LICENSE    \u001b[01;32mpreprocess.py\u001b[0m*  utility.py\n",
            "download.py        \u001b[01;32mmodel.py\u001b[0m*  README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XNziVZ0scTv",
        "outputId": "ef14ae01-7212-4348-be13-cc5d084959d8"
      },
      "source": [
        "%cat README.md"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "## StarGAN Voice Conversion\n",
            "\n",
            "This is a tensorflow implementation of the paper: [StarGAN-VC: Non-parallel many-to-many voice conversion with star generative adversarial networks](https://arxiv.org/abs/1806.02169).\n",
            "\n",
            "\n",
            "\n",
            "**The converted voice examples are in *converted* directory**\n",
            "\n",
            "## Dependencies\n",
            "\n",
            "- Python 3.6 (or higher)\n",
            "- tensorflow 1.8\n",
            "- librosa \n",
            "- pyworld \n",
            "- tensorboard\n",
            "- scikit-learn\n",
            "\n",
            "> NOTE:According to some feedbacks, we recommend to use tensorflow version 1.8  exactly. (Tensorflow 1.11 generate nonsense results)\n",
            "\n",
            "## Usage\n",
            "\n",
            "#### Download dataset\n",
            "\n",
            "Download the vcc 2016 dataset to the current directory and create `train directory` and `test directory`.\n",
            "\n",
            "```\n",
            "python download.py --datasets vcc2016 --train_dir ./data/fourspeakers --test_dir ./data/fourspeakers_test\n",
            "\n",
            "For simplicity use:\n",
            "python download.py \n",
            "```\n",
            "\n",
            "The downloaded zip files are extracted to `./data/vcc2016_training` and `./data/evaluation_all`.\n",
            "\n",
            "1. **training set:** In the experiment, we choose **four speakers** from `./data/vcc2016_training`.  We  move the corresponding folder(eg. SF1,SF2,TM1,TM2 ) to `./data/fourspeakers`.\n",
            "2. **testing set** In the experiment, we choose **four speakers** from `./data/evaluation_all`.  We  move the corresponding folder(eg. SF1,SF2,TM1,TM2 ) to `./data/fourspeakers_test`.\n",
            "\n",
            "The data directory now looks like this:\n",
            "\n",
            "```\n",
            "data\n",
            "├── fourspeakers  (training set)\n",
            "│   ├── SF1\n",
            "│   ├── SF2\n",
            "│   ├── TM1\n",
            "│   └── TM2\n",
            "├── fourspeakers_test (testing set)\n",
            "│   ├── SF1\n",
            "│   ├── SF2\n",
            "│   ├── TM1\n",
            "│   └── TM2\n",
            "├── vcc2016_training (vcc 2016 training set)\n",
            "│   ├── ...\n",
            "├── evaluation_all (vcc 2016 evaluation set, we use it as testing set)\n",
            "│   ├── ...\n",
            "```\n",
            "\n",
            "\n",
            "\n",
            "#### Preprocess dataset\n",
            "\n",
            "Extract features (mcep, f0, ap) from each speech clip.  The features are stored as npy files. We also calculate the statistical characteristics for each speaker.\n",
            "\n",
            "```\n",
            "python preprocess.py --input_dir ./data/fourspeakers --output_dir ./data/processed --ispad True\n",
            "\n",
            "For simplicity use:\n",
            "python preprocess.py\n",
            "```\n",
            "\n",
            "This process may take a few minutes !\n",
            "\n",
            "**Note that test set doesn’t need preprocess.**\n",
            "\n",
            "\n",
            "\n",
            "#### Train\n",
            "\n",
            "Read npy files from `processed_dir` to train model and raw wav files from` test_wav_dir` to randomly generate some samples using the model during training.\n",
            "\n",
            "```\n",
            "python train.py --processed_dir ./data/processed --test_wav_dir ./data/fourspeakers_test\n",
            "\n",
            "For simplicity use:\n",
            "python train.py\n",
            "```\n",
            "\n",
            "\n",
            "\n",
            "#### Convert\n",
            "\n",
            "Restore model from `model_dir`, convert source_speaker’s speech to target_speaker’s speech. The results are strored in `./converted_voices`\n",
            "\n",
            "```\n",
            "python convert.py --model_dir ./your_model_dir  --source_speaker SF1 --target_speaker TM1\n",
            "```\n",
            "\n",
            "\n",
            "\n",
            "## Summary\n",
            "\n",
            "The network structure shown as follows:\n",
            "\n",
            "![Snip20181102_2](./imgs/Snip20181102_2.png)\n",
            "\n",
            "\n",
            "\n",
            "**Note: Our implementation follows the original paper’s network structure**, while [pytorch StarGAN-VC code](https://github.com/liusongxiang/StarGAN-Voice-Conversion)‘network is different from the paper as it’s classifier shares the Discriminator’s weights. Both ways generate good converted speeches.\n",
            "\n",
            "## Reference\n",
            "\n",
            "[CycleGAN-VC code](https://github.com/leimao/Voice_Converter_CycleGAN)\n",
            "\n",
            "[pytorch StarGAN-VC code](https://github.com/hujinsen/pytorch-StarGAN-VC)\n",
            "\n",
            "[StarGAN code](https://github.com/taki0112/StarGAN-Tensorflow)\n",
            "\n",
            "[StarGAN-VC paper](https://arxiv.org/abs/1806.02169)\n",
            "\n",
            "[StarGAN paper](https://arxiv.org/abs/1806.02169)\n",
            "\n",
            "[CycleGAN paper](https://arxiv.org/abs/1703.10593v4)\n",
            "\n",
            "---\n",
            "\n",
            "If you feel this repo is good, please  **star**  ! \n",
            "\n",
            "Your encouragement is my biggest motivation!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJuF8mV6snQ3",
        "outputId": "90c7f6de-fb91-4155-af13-44062f8112c6"
      },
      "source": [
        "!pip3 install librosa pyworld tensorboard scikit-learn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.0)\n",
            "Requirement already satisfied: pyworld in /usr/local/lib/python3.7/dist-packages (0.2.12)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (0.22.2.post1)\n",
            "Requirement already satisfied: soundfile>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.3.0)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.1)\n",
            "Requirement already satisfied: cython>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from pyworld) (0.29.21)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.15.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.8.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.36.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (53.0.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.32.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.4.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.10.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.12.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (2.23.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.27.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.3.3)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.9.0->librosa) (1.14.5)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (20.9)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (4.7.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (4.2.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard) (3.4.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.9.0->librosa) (2.20)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pooch>=1.0->librosa) (2.4.7)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard) (3.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5x6wzatEs01c",
        "outputId": "022a84e5-7f46-45e7-ae2c-8f72a1e00699"
      },
      "source": [
        "%tensorflow_version 1.8\r\n",
        "import tensorflow\r\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.8`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n",
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hng1DgLltMGg",
        "outputId": "5491154a-f8ad-41bf-9bd1-028eba108204"
      },
      "source": [
        "# !pip install tensorflow==1.8.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==1.8.0 (from versions: 1.13.0rc1, 1.13.0rc2, 1.13.1, 1.13.2, 1.14.0rc0, 1.14.0rc1, 1.14.0, 1.15.0rc0, 1.15.0rc1, 1.15.0rc2, 1.15.0rc3, 1.15.0, 1.15.2, 1.15.3, 1.15.4, 1.15.5, 2.0.0a0, 2.0.0b0, 2.0.0b1, 2.0.0rc0, 2.0.0rc1, 2.0.0rc2, 2.0.0, 2.0.1, 2.0.2, 2.0.3, 2.0.4, 2.1.0rc0, 2.1.0rc1, 2.1.0rc2, 2.1.0, 2.1.1, 2.1.2, 2.1.3, 2.2.0rc0, 2.2.0rc1, 2.2.0rc2, 2.2.0rc3, 2.2.0rc4, 2.2.0, 2.2.1, 2.2.2, 2.3.0rc0, 2.3.0rc1, 2.3.0rc2, 2.3.0, 2.3.1, 2.3.2, 2.4.0rc0, 2.4.0rc1, 2.4.0rc2, 2.4.0rc3, 2.4.0rc4, 2.4.0, 2.4.1)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for tensorflow==1.8.0\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iD9poUZrt1Mb",
        "outputId": "e11a5520-7fba-449e-e541-5a9a7b7c1b6f"
      },
      "source": [
        "!python download.py --datasets vcc2016 --train_dir ./data/fourspeakers --test_dir ./data/fourspeakers_test\r\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "create train set dir ./data/fourspeakers\n",
            "create test set dir ./data/fourspeakers_test\n",
            "Start download dataset...\n",
            "Extraction complete!\n",
            "Extraction complete!\n",
            "Finish download dataset...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxM6Bh4ru8_b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1b86c48-9b10-4572-feab-11eda43026f6"
      },
      "source": [
        "!ls\r\n",
        "!rm -r evaluation_all "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "converted_speech  evaluation_all      __MACOSX\t     README.md\n",
            "convert.py\t  evaluation_all.zip  model.py\t     train.py\n",
            "data\t\t  imgs\t\t      module.py      utility.py\n",
            "download.py\t  LICENSE\t      preprocess.py  vcc2016_training.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opims8GbwwaJ",
        "outputId": "448b4494-0d9e-4ffe-e753-dbd2dfc4211e"
      },
      "source": [
        "!cat README.md"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "## StarGAN Voice Conversion\n",
            "\n",
            "This is a tensorflow implementation of the paper: [StarGAN-VC: Non-parallel many-to-many voice conversion with star generative adversarial networks](https://arxiv.org/abs/1806.02169).\n",
            "\n",
            "\n",
            "\n",
            "**The converted voice examples are in *converted* directory**\n",
            "\n",
            "## Dependencies\n",
            "\n",
            "- Python 3.6 (or higher)\n",
            "- tensorflow 1.8\n",
            "- librosa \n",
            "- pyworld \n",
            "- tensorboard\n",
            "- scikit-learn\n",
            "\n",
            "> NOTE:According to some feedbacks, we recommend to use tensorflow version 1.8  exactly. (Tensorflow 1.11 generate nonsense results)\n",
            "\n",
            "## Usage\n",
            "\n",
            "#### Download dataset\n",
            "\n",
            "Download the vcc 2016 dataset to the current directory and create `train directory` and `test directory`.\n",
            "\n",
            "```\n",
            "python download.py --datasets vcc2016 --train_dir ./data/fourspeakers --test_dir ./data/fourspeakers_test\n",
            "\n",
            "For simplicity use:\n",
            "python download.py \n",
            "```\n",
            "\n",
            "The downloaded zip files are extracted to `./data/vcc2016_training` and `./data/evaluation_all`.\n",
            "\n",
            "1. **training set:** In the experiment, we choose **four speakers** from `./data/vcc2016_training`.  We  move the corresponding folder(eg. SF1,SF2,TM1,TM2 ) to `./data/fourspeakers`.\n",
            "2. **testing set** In the experiment, we choose **four speakers** from `./data/evaluation_all`.  We  move the corresponding folder(eg. SF1,SF2,TM1,TM2 ) to `./data/fourspeakers_test`.\n",
            "\n",
            "The data directory now looks like this:\n",
            "\n",
            "```\n",
            "data\n",
            "├── fourspeakers  (training set)\n",
            "│   ├── SF1\n",
            "│   ├── SF2\n",
            "│   ├── TM1\n",
            "│   └── TM2\n",
            "├── fourspeakers_test (testing set)\n",
            "│   ├── SF1\n",
            "│   ├── SF2\n",
            "│   ├── TM1\n",
            "│   └── TM2\n",
            "├── vcc2016_training (vcc 2016 training set)\n",
            "│   ├── ...\n",
            "├── evaluation_all (vcc 2016 evaluation set, we use it as testing set)\n",
            "│   ├── ...\n",
            "```\n",
            "\n",
            "\n",
            "\n",
            "#### Preprocess dataset\n",
            "\n",
            "Extract features (mcep, f0, ap) from each speech clip.  The features are stored as npy files. We also calculate the statistical characteristics for each speaker.\n",
            "\n",
            "```\n",
            "python preprocess.py --input_dir ./data/fourspeakers --output_dir ./data/processed --ispad True\n",
            "\n",
            "For simplicity use:\n",
            "python preprocess.py\n",
            "```\n",
            "\n",
            "This process may take a few minutes !\n",
            "\n",
            "**Note that test set doesn’t need preprocess.**\n",
            "\n",
            "\n",
            "\n",
            "#### Train\n",
            "\n",
            "Read npy files from `processed_dir` to train model and raw wav files from` test_wav_dir` to randomly generate some samples using the model during training.\n",
            "\n",
            "```\n",
            "python train.py --processed_dir ./data/processed --test_wav_dir ./data/fourspeakers_test\n",
            "\n",
            "For simplicity use:\n",
            "python train.py\n",
            "```\n",
            "\n",
            "\n",
            "\n",
            "#### Convert\n",
            "\n",
            "Restore model from `model_dir`, convert source_speaker’s speech to target_speaker’s speech. The results are strored in `./converted_voices`\n",
            "\n",
            "```\n",
            "python convert.py --model_dir ./your_model_dir  --source_speaker SF1 --target_speaker TM1\n",
            "```\n",
            "\n",
            "\n",
            "\n",
            "## Summary\n",
            "\n",
            "The network structure shown as follows:\n",
            "\n",
            "![Snip20181102_2](./imgs/Snip20181102_2.png)\n",
            "\n",
            "\n",
            "\n",
            "**Note: Our implementation follows the original paper’s network structure**, while [pytorch StarGAN-VC code](https://github.com/liusongxiang/StarGAN-Voice-Conversion)‘network is different from the paper as it’s classifier shares the Discriminator’s weights. Both ways generate good converted speeches.\n",
            "\n",
            "## Reference\n",
            "\n",
            "[CycleGAN-VC code](https://github.com/leimao/Voice_Converter_CycleGAN)\n",
            "\n",
            "[pytorch StarGAN-VC code](https://github.com/hujinsen/pytorch-StarGAN-VC)\n",
            "\n",
            "[StarGAN code](https://github.com/taki0112/StarGAN-Tensorflow)\n",
            "\n",
            "[StarGAN-VC paper](https://arxiv.org/abs/1806.02169)\n",
            "\n",
            "[StarGAN paper](https://arxiv.org/abs/1806.02169)\n",
            "\n",
            "[CycleGAN paper](https://arxiv.org/abs/1703.10593v4)\n",
            "\n",
            "---\n",
            "\n",
            "If you feel this repo is good, please  **star**  ! \n",
            "\n",
            "Your encouragement is my biggest motivation!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4l31Hsszuj3"
      },
      "source": [
        "copy data to respectiv folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrQksC8RzuL_",
        "outputId": "e24969b1-6751-4756-c2da-598fcda43b87"
      },
      "source": [
        "%mv  \"data/vcc2016_training/SF1\" data/fourspeakers\r\n",
        "%mv  \"data/vcc2016_training/SF2\" data/fourspeakers\r\n",
        "%mv  \"data/vcc2016_training/TM1\" data/fourspeakers\r\n",
        "%mv  \"data/vcc2016_training/TM2\" data/fourspeakers\r\n",
        "\r\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mv: cannot stat 'data/vcc2016_training/SF1': No such file or directory\n",
            "mv: cannot stat 'data/vcc2016_training/SF2': No such file or directory\n",
            "mv: cannot stat 'data/vcc2016_training/TM1': No such file or directory\n",
            "mv: cannot stat 'data/vcc2016_training/TM2': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8dJeJ0b1EUO"
      },
      "source": [
        "%mv  \"data/evaluation_all/SF1\" data/fourspeakers_test\r\n",
        "%mv  \"data/evaluation_all/SF2\" data/fourspeakers_test\r\n",
        "%mv  \"data/evaluation_all/TM1\" data/fourspeakers_test\r\n",
        "%mv  \"data/evaluation_all/TM2\" data/fourspeakers_test"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLEmOG3V0MWz",
        "outputId": "5a545582-fdfd-4ff6-da36-61e37c2a4792"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "converted_speech  evaluation_all.zip  module.py      utility.py\n",
            "convert.py\t  imgs\t\t      preprocess.py  vcc2016_training.zip\n",
            "data\t\t  LICENSE\t      __pycache__\n",
            "download.py\t  __MACOSX\t      README.md\n",
            "etc\t\t  model.py\t      train.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r23DVwqRxq_c"
      },
      "source": [
        "Extract features "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3XjLuAUxB0s",
        "outputId": "0b74ed05-dc6b-47b2-e875-68f4881a8f9e"
      },
      "source": [
        "!python preprocess.py --input_dir ./data/fourspeakers --output_dir ./data/processed --ispad True"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total 648 audio files!\n",
            "loaded keys: dict_keys(['TM2', 'SF2', 'TM1', 'SF1'])\n",
            "........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "Total 648 aduio files!\n",
            "save file: ./data/processed/TM2-100151\n",
            "audio mcep shape (36, 1024)\n",
            "[1:648]svaing file: ./data/processed/TM2-100151_0.npy\n",
            "[1:648]svaing file: ./data/processed/TM2-100151_512.npy\n",
            "save file: ./data/processed/TM2-100090\n",
            "audio mcep shape (36, 512)\n",
            "[2:648]svaing file: ./data/processed/TM2-100090_0.npy\n",
            "save file: ./data/processed/TM2-100081\n",
            "audio mcep shape (36, 1536)\n",
            "[3:648]svaing file: ./data/processed/TM2-100081_0.npy\n",
            "[3:648]svaing file: ./data/processed/TM2-100081_512.npy\n",
            "[3:648]svaing file: ./data/processed/TM2-100081_1024.npy\n",
            "save file: ./data/processed/TM2-100006\n",
            "audio mcep shape (36, 1024)\n",
            "[4:648]svaing file: ./data/processed/TM2-100006_0.npy\n",
            "[4:648]svaing file: ./data/processed/TM2-100006_512.npy\n",
            "save file: ./data/processed/TM2-100013\n",
            "audio mcep shape (36, 1024)\n",
            "[5:648]svaing file: ./data/processed/TM2-100013_0.npy\n",
            "[5:648]svaing file: ./data/processed/TM2-100013_512.npy\n",
            "save file: ./data/processed/TM2-100110\n",
            "audio mcep shape (36, 1024)\n",
            "[6:648]svaing file: ./data/processed/TM2-100110_0.npy\n",
            "[6:648]svaing file: ./data/processed/TM2-100110_512.npy\n",
            "save file: ./data/processed/TM2-100002\n",
            "audio mcep shape (36, 512)\n",
            "[7:648]svaing file: ./data/processed/TM2-100002_0.npy\n",
            "save file: ./data/processed/TM2-100101\n",
            "audio mcep shape (36, 1024)\n",
            "[8:648]svaing file: ./data/processed/TM2-100101_0.npy\n",
            "[8:648]svaing file: ./data/processed/TM2-100101_512.npy\n",
            "save file: ./data/processed/TM2-100083\n",
            "audio mcep shape (36, 1024)\n",
            "[9:648]svaing file: ./data/processed/TM2-100083_0.npy\n",
            "[9:648]svaing file: ./data/processed/TM2-100083_512.npy\n",
            "save file: ./data/processed/TM2-100122\n",
            "audio mcep shape (36, 512)\n",
            "[10:648]svaing file: ./data/processed/TM2-100122_0.npy\n",
            "save file: ./data/processed/TM2-100025\n",
            "audio mcep shape (36, 1536)\n",
            "[11:648]svaing file: ./data/processed/TM2-100025_0.npy\n",
            "[11:648]svaing file: ./data/processed/TM2-100025_512.npy\n",
            "[11:648]svaing file: ./data/processed/TM2-100025_1024.npy\n",
            "save file: ./data/processed/TM2-100161\n",
            "audio mcep shape (36, 1024)\n",
            "[12:648]svaing file: ./data/processed/TM2-100161_0.npy\n",
            "[12:648]svaing file: ./data/processed/TM2-100161_512.npy\n",
            "save file: ./data/processed/TM2-100131\n",
            "audio mcep shape (36, 1024)\n",
            "[13:648]svaing file: ./data/processed/TM2-100131_0.npy\n",
            "[13:648]svaing file: ./data/processed/TM2-100131_512.npy\n",
            "save file: ./data/processed/TM2-100156\n",
            "audio mcep shape (36, 512)\n",
            "[14:648]svaing file: ./data/processed/TM2-100156_0.npy\n",
            "save file: ./data/processed/TM2-100150\n",
            "audio mcep shape (36, 512)\n",
            "[15:648]svaing file: ./data/processed/TM2-100150_0.npy\n",
            "save file: ./data/processed/TM2-100064\n",
            "audio mcep shape (36, 1024)\n",
            "[16:648]svaing file: ./data/processed/TM2-100064_0.npy\n",
            "[16:648]svaing file: ./data/processed/TM2-100064_512.npy\n",
            "save file: ./data/processed/TM2-100031\n",
            "audio mcep shape (36, 512)\n",
            "[17:648]svaing file: ./data/processed/TM2-100031_0.npy\n",
            "save file: ./data/processed/TM2-100140\n",
            "audio mcep shape (36, 512)\n",
            "[18:648]svaing file: ./data/processed/TM2-100140_0.npy\n",
            "save file: ./data/processed/TM2-100053\n",
            "audio mcep shape (36, 512)\n",
            "[19:648]svaing file: ./data/processed/TM2-100053_0.npy\n",
            "save file: ./data/processed/TM2-100007\n",
            "audio mcep shape (36, 512)\n",
            "[20:648]svaing file: ./data/processed/TM2-100007_0.npy\n",
            "save file: ./data/processed/TM2-100118\n",
            "audio mcep shape (36, 1024)\n",
            "[21:648]svaing file: ./data/processed/TM2-100118_0.npy\n",
            "[21:648]svaing file: ./data/processed/TM2-100118_512.npy\n",
            "save file: ./data/processed/TM2-100154\n",
            "audio mcep shape (36, 512)\n",
            "[22:648]svaing file: ./data/processed/TM2-100154_0.npy\n",
            "save file: ./data/processed/TM2-100124\n",
            "audio mcep shape (36, 512)\n",
            "[23:648]svaing file: ./data/processed/TM2-100124_0.npy\n",
            "save file: ./data/processed/TM2-100104\n",
            "audio mcep shape (36, 512)\n",
            "[24:648]svaing file: ./data/processed/TM2-100104_0.npy\n",
            "save file: ./data/processed/TM2-100108\n",
            "audio mcep shape (36, 1024)\n",
            "[25:648]svaing file: ./data/processed/TM2-100108_0.npy\n",
            "[25:648]svaing file: ./data/processed/TM2-100108_512.npy\n",
            "save file: ./data/processed/TM2-100040\n",
            "audio mcep shape (36, 1024)\n",
            "[26:648]svaing file: ./data/processed/TM2-100040_0.npy\n",
            "[26:648]svaing file: ./data/processed/TM2-100040_512.npy\n",
            "save file: ./data/processed/TM2-100010\n",
            "audio mcep shape (36, 1024)\n",
            "[27:648]svaing file: ./data/processed/TM2-100010_0.npy\n",
            "[27:648]svaing file: ./data/processed/TM2-100010_512.npy\n",
            "save file: ./data/processed/TM2-100072\n",
            "audio mcep shape (36, 1024)\n",
            "[28:648]svaing file: ./data/processed/TM2-100072_0.npy\n",
            "[28:648]svaing file: ./data/processed/TM2-100072_512.npy\n",
            "save file: ./data/processed/TM2-100103\n",
            "audio mcep shape (36, 512)\n",
            "[29:648]svaing file: ./data/processed/TM2-100103_0.npy\n",
            "save file: ./data/processed/TM2-100055\n",
            "audio mcep shape (36, 512)\n",
            "[30:648]svaing file: ./data/processed/TM2-100055_0.npy\n",
            "save file: ./data/processed/TM2-100048\n",
            "audio mcep shape (36, 1024)\n",
            "[31:648]svaing file: ./data/processed/TM2-100048_0.npy\n",
            "[31:648]svaing file: ./data/processed/TM2-100048_512.npy\n",
            "save file: ./data/processed/TM2-100041\n",
            "audio mcep shape (36, 512)\n",
            "[32:648]svaing file: ./data/processed/TM2-100041_0.npy\n",
            "save file: ./data/processed/TM2-100155\n",
            "audio mcep shape (36, 1024)\n",
            "[33:648]svaing file: ./data/processed/TM2-100155_0.npy\n",
            "[33:648]svaing file: ./data/processed/TM2-100155_512.npy\n",
            "save file: ./data/processed/TM2-100032\n",
            "audio mcep shape (36, 1024)\n",
            "[34:648]svaing file: ./data/processed/TM2-100032_0.npy\n",
            "[34:648]svaing file: ./data/processed/TM2-100032_512.npy\n",
            "save file: ./data/processed/TM2-100076\n",
            "audio mcep shape (36, 512)\n",
            "[35:648]svaing file: ./data/processed/TM2-100076_0.npy\n",
            "save file: ./data/processed/TM2-100073\n",
            "audio mcep shape (36, 1024)\n",
            "[36:648]svaing file: ./data/processed/TM2-100073_0.npy\n",
            "[36:648]svaing file: ./data/processed/TM2-100073_512.npy\n",
            "save file: ./data/processed/TM2-100065\n",
            "audio mcep shape (36, 1024)\n",
            "[37:648]svaing file: ./data/processed/TM2-100065_0.npy\n",
            "[37:648]svaing file: ./data/processed/TM2-100065_512.npy\n",
            "save file: ./data/processed/TM2-100149\n",
            "audio mcep shape (36, 1536)\n",
            "[38:648]svaing file: ./data/processed/TM2-100149_0.npy\n",
            "[38:648]svaing file: ./data/processed/TM2-100149_512.npy\n",
            "[38:648]svaing file: ./data/processed/TM2-100149_1024.npy\n",
            "save file: ./data/processed/TM2-100066\n",
            "audio mcep shape (36, 512)\n",
            "[39:648]svaing file: ./data/processed/TM2-100066_0.npy\n",
            "save file: ./data/processed/TM2-100030\n",
            "audio mcep shape (36, 512)\n",
            "[40:648]svaing file: ./data/processed/TM2-100030_0.npy\n",
            "save file: ./data/processed/TM2-100145\n",
            "audio mcep shape (36, 512)\n",
            "[41:648]svaing file: ./data/processed/TM2-100145_0.npy\n",
            "save file: ./data/processed/TM2-100139\n",
            "audio mcep shape (36, 512)\n",
            "[42:648]svaing file: ./data/processed/TM2-100139_0.npy\n",
            "save file: ./data/processed/TM2-100134\n",
            "audio mcep shape (36, 512)\n",
            "[43:648]svaing file: ./data/processed/TM2-100134_0.npy\n",
            "save file: ./data/processed/TM2-100085\n",
            "audio mcep shape (36, 1024)\n",
            "[44:648]svaing file: ./data/processed/TM2-100085_0.npy\n",
            "[44:648]svaing file: ./data/processed/TM2-100085_512.npy\n",
            "save file: ./data/processed/TM2-100115\n",
            "audio mcep shape (36, 1024)\n",
            "[45:648]svaing file: ./data/processed/TM2-100115_0.npy\n",
            "[45:648]svaing file: ./data/processed/TM2-100115_512.npy\n",
            "save file: ./data/processed/TM2-100123\n",
            "audio mcep shape (36, 1024)\n",
            "[46:648]svaing file: ./data/processed/TM2-100123_0.npy\n",
            "[46:648]svaing file: ./data/processed/TM2-100123_512.npy\n",
            "save file: ./data/processed/TM2-100042\n",
            "audio mcep shape (36, 1024)\n",
            "[47:648]svaing file: ./data/processed/TM2-100042_0.npy\n",
            "[47:648]svaing file: ./data/processed/TM2-100042_512.npy\n",
            "save file: ./data/processed/TM2-100099\n",
            "audio mcep shape (36, 1024)\n",
            "[48:648]svaing file: ./data/processed/TM2-100099_0.npy\n",
            "[48:648]svaing file: ./data/processed/TM2-100099_512.npy\n",
            "save file: ./data/processed/TM2-100138\n",
            "audio mcep shape (36, 512)\n",
            "[49:648]svaing file: ./data/processed/TM2-100138_0.npy\n",
            "save file: ./data/processed/TM2-100088\n",
            "audio mcep shape (36, 1536)\n",
            "[50:648]svaing file: ./data/processed/TM2-100088_0.npy\n",
            "[50:648]svaing file: ./data/processed/TM2-100088_512.npy\n",
            "[50:648]svaing file: ./data/processed/TM2-100088_1024.npy\n",
            "save file: ./data/processed/TM2-100135\n",
            "audio mcep shape (36, 1024)\n",
            "[51:648]svaing file: ./data/processed/TM2-100135_0.npy\n",
            "[51:648]svaing file: ./data/processed/TM2-100135_512.npy\n",
            "save file: ./data/processed/TM2-100029\n",
            "audio mcep shape (36, 1024)\n",
            "[52:648]svaing file: ./data/processed/TM2-100029_0.npy\n",
            "[52:648]svaing file: ./data/processed/TM2-100029_512.npy\n",
            "save file: ./data/processed/TM2-100121\n",
            "audio mcep shape (36, 1024)\n",
            "[53:648]svaing file: ./data/processed/TM2-100121_0.npy\n",
            "[53:648]svaing file: ./data/processed/TM2-100121_512.npy\n",
            "save file: ./data/processed/TM2-100142\n",
            "audio mcep shape (36, 1024)\n",
            "[54:648]svaing file: ./data/processed/TM2-100142_0.npy\n",
            "[54:648]svaing file: ./data/processed/TM2-100142_512.npy\n",
            "save file: ./data/processed/TM2-100058\n",
            "audio mcep shape (36, 512)\n",
            "[55:648]svaing file: ./data/processed/TM2-100058_0.npy\n",
            "save file: ./data/processed/TM2-100003\n",
            "audio mcep shape (36, 512)\n",
            "[56:648]svaing file: ./data/processed/TM2-100003_0.npy\n",
            "save file: ./data/processed/TM2-100136\n",
            "audio mcep shape (36, 1024)\n",
            "[57:648]svaing file: ./data/processed/TM2-100136_0.npy\n",
            "[57:648]svaing file: ./data/processed/TM2-100136_512.npy\n",
            "save file: ./data/processed/TM2-100044\n",
            "audio mcep shape (36, 512)\n",
            "[58:648]svaing file: ./data/processed/TM2-100044_0.npy\n",
            "save file: ./data/processed/TM2-100061\n",
            "audio mcep shape (36, 1024)\n",
            "[59:648]svaing file: ./data/processed/TM2-100061_0.npy\n",
            "[59:648]svaing file: ./data/processed/TM2-100061_512.npy\n",
            "save file: ./data/processed/TM2-100071\n",
            "audio mcep shape (36, 1024)\n",
            "[60:648]svaing file: ./data/processed/TM2-100071_0.npy\n",
            "[60:648]svaing file: ./data/processed/TM2-100071_512.npy\n",
            "save file: ./data/processed/TM2-100111\n",
            "audio mcep shape (36, 1024)\n",
            "[61:648]svaing file: ./data/processed/TM2-100111_0.npy\n",
            "[61:648]svaing file: ./data/processed/TM2-100111_512.npy\n",
            "save file: ./data/processed/TM2-100018\n",
            "audio mcep shape (36, 512)\n",
            "[62:648]svaing file: ./data/processed/TM2-100018_0.npy\n",
            "save file: ./data/processed/TM2-100037\n",
            "audio mcep shape (36, 512)\n",
            "[63:648]svaing file: ./data/processed/TM2-100037_0.npy\n",
            "save file: ./data/processed/TM2-100093\n",
            "audio mcep shape (36, 512)\n",
            "[64:648]svaing file: ./data/processed/TM2-100093_0.npy\n",
            "save file: ./data/processed/TM2-100105\n",
            "audio mcep shape (36, 1024)\n",
            "[65:648]svaing file: ./data/processed/TM2-100105_0.npy\n",
            "[65:648]svaing file: ./data/processed/TM2-100105_512.npy\n",
            "save file: ./data/processed/TM2-100060\n",
            "audio mcep shape (36, 512)\n",
            "[66:648]svaing file: ./data/processed/TM2-100060_0.npy\n",
            "save file: ./data/processed/TM2-100012\n",
            "audio mcep shape (36, 1024)\n",
            "[67:648]svaing file: ./data/processed/TM2-100012_0.npy\n",
            "[67:648]svaing file: ./data/processed/TM2-100012_512.npy\n",
            "save file: ./data/processed/TM2-100015\n",
            "audio mcep shape (36, 512)\n",
            "[68:648]svaing file: ./data/processed/TM2-100015_0.npy\n",
            "save file: ./data/processed/TM2-100017\n",
            "audio mcep shape (36, 1024)\n",
            "[69:648]svaing file: ./data/processed/TM2-100017_0.npy\n",
            "[69:648]svaing file: ./data/processed/TM2-100017_512.npy\n",
            "save file: ./data/processed/TM2-100141\n",
            "audio mcep shape (36, 512)\n",
            "[70:648]svaing file: ./data/processed/TM2-100141_0.npy\n",
            "save file: ./data/processed/TM2-100126\n",
            "audio mcep shape (36, 1024)\n",
            "[71:648]svaing file: ./data/processed/TM2-100126_0.npy\n",
            "[71:648]svaing file: ./data/processed/TM2-100126_512.npy\n",
            "save file: ./data/processed/TM2-100095\n",
            "audio mcep shape (36, 1024)\n",
            "[72:648]svaing file: ./data/processed/TM2-100095_0.npy\n",
            "[72:648]svaing file: ./data/processed/TM2-100095_512.npy\n",
            "save file: ./data/processed/TM2-100068\n",
            "audio mcep shape (36, 512)\n",
            "[73:648]svaing file: ./data/processed/TM2-100068_0.npy\n",
            "save file: ./data/processed/TM2-100075\n",
            "audio mcep shape (36, 1024)\n",
            "[74:648]svaing file: ./data/processed/TM2-100075_0.npy\n",
            "[74:648]svaing file: ./data/processed/TM2-100075_512.npy\n",
            "save file: ./data/processed/TM2-100120\n",
            "audio mcep shape (36, 1024)\n",
            "[75:648]svaing file: ./data/processed/TM2-100120_0.npy\n",
            "[75:648]svaing file: ./data/processed/TM2-100120_512.npy\n",
            "save file: ./data/processed/TM2-100063\n",
            "audio mcep shape (36, 512)\n",
            "[76:648]svaing file: ./data/processed/TM2-100063_0.npy\n",
            "save file: ./data/processed/TM2-100157\n",
            "audio mcep shape (36, 1024)\n",
            "[77:648]svaing file: ./data/processed/TM2-100157_0.npy\n",
            "[77:648]svaing file: ./data/processed/TM2-100157_512.npy\n",
            "save file: ./data/processed/TM2-100001\n",
            "audio mcep shape (36, 1024)\n",
            "[78:648]svaing file: ./data/processed/TM2-100001_0.npy\n",
            "[78:648]svaing file: ./data/processed/TM2-100001_512.npy\n",
            "save file: ./data/processed/TM2-100050\n",
            "audio mcep shape (36, 1024)\n",
            "[79:648]svaing file: ./data/processed/TM2-100050_0.npy\n",
            "[79:648]svaing file: ./data/processed/TM2-100050_512.npy\n",
            "save file: ./data/processed/TM2-100080\n",
            "audio mcep shape (36, 1024)\n",
            "[80:648]svaing file: ./data/processed/TM2-100080_0.npy\n",
            "[80:648]svaing file: ./data/processed/TM2-100080_512.npy\n",
            "save file: ./data/processed/TM2-100069\n",
            "audio mcep shape (36, 512)\n",
            "[81:648]svaing file: ./data/processed/TM2-100069_0.npy\n",
            "save file: ./data/processed/TM2-100146\n",
            "audio mcep shape (36, 512)\n",
            "[82:648]svaing file: ./data/processed/TM2-100146_0.npy\n",
            "save file: ./data/processed/TM2-100089\n",
            "audio mcep shape (36, 512)\n",
            "[83:648]svaing file: ./data/processed/TM2-100089_0.npy\n",
            "save file: ./data/processed/TM2-100033\n",
            "audio mcep shape (36, 1024)\n",
            "[84:648]svaing file: ./data/processed/TM2-100033_0.npy\n",
            "[84:648]svaing file: ./data/processed/TM2-100033_512.npy\n",
            "save file: ./data/processed/TM2-100100\n",
            "audio mcep shape (36, 1024)\n",
            "[85:648]svaing file: ./data/processed/TM2-100100_0.npy\n",
            "[85:648]svaing file: ./data/processed/TM2-100100_512.npy\n",
            "save file: ./data/processed/TM2-100036\n",
            "audio mcep shape (36, 512)\n",
            "[86:648]svaing file: ./data/processed/TM2-100036_0.npy\n",
            "save file: ./data/processed/TM2-100119\n",
            "audio mcep shape (36, 512)\n",
            "[87:648]svaing file: ./data/processed/TM2-100119_0.npy\n",
            "save file: ./data/processed/TM2-100117\n",
            "audio mcep shape (36, 512)\n",
            "[88:648]svaing file: ./data/processed/TM2-100117_0.npy\n",
            "save file: ./data/processed/TM2-100114\n",
            "audio mcep shape (36, 1536)\n",
            "[89:648]svaing file: ./data/processed/TM2-100114_0.npy\n",
            "[89:648]svaing file: ./data/processed/TM2-100114_512.npy\n",
            "[89:648]svaing file: ./data/processed/TM2-100114_1024.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWBCHiY1zJL1"
      },
      "source": [
        "train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W79msPchyIDJ",
        "outputId": "4793a64b-4365-4c49-ef95-8b54c1a9e381"
      },
      "source": [
        "!python train.py --processed_dir ./data/processed --test_wav_dir ./data/fourspeakers_test\r\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Data...\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 262, in <module>\n",
            "    train(processed_dir, test_wav_dir)\n",
            "  File \"train.py\", line 46, in train\n",
            "    assert len(files) > 0\n",
            "AssertionError\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5jXV4dK1qLO"
      },
      "source": [
        "%rm  data/converted_speech/*.wav"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iVHJHNhzN0G"
      },
      "source": [
        "Convert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLL0x_G8zLaa",
        "outputId": "a50f58df-e777-4235-9c32-5df492fb7b6f"
      },
      "source": [
        "!python convert.py --model_dir ./your_model_dir  --source_speaker SF1 --target_speaker TM1"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"convert.py\", line 129, in <module>\n",
            "    test_dir = test_dir, output_dir = output_dir, source=source_speaker, target=target_speaker)\n",
            "  File \"convert.py\", line 18, in conversion\n",
            "    raise Exception('model dir or test dir not exist!')\n",
            "Exception: model dir or test dir not exist!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swQR9WP_zk0Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}